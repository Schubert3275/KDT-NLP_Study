{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Soynlp] 학습 기반 토크나이저 <hr>\n",
    "\n",
    "-   품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저\n",
    "-   비지도 학습으로 단어 토큰화 ==> 데이터에 자주 등장하는 단어들을 단어로 분석\n",
    "-   내부적으로 단어 점수 표로 동작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install soynlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [기존 형태소 분석기]: 신조어나 형태소 분석기에 등록되지 않은 단어 제대로 구분하지 못함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정', '입니다']\n",
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정', '이다']\n",
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정', '입니다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "tokenizer = Okt()\n",
    "\n",
    "print(tokenizer.morphs(\"에이비식스 이대휘 1월 최애돌 기부 요정 입니다\"))\n",
    "\n",
    "## 형태소 분석 시 매개변수 stem=Trur 설정\n",
    "print(tokenizer.morphs(\"에이비식스 이대휘 1월 최애돌 기부 요정 입니다\", stem=True))\n",
    "\n",
    "print(tokenizer.morphs(\"에이비식스 이대휘 1월 최애돌 기부 요정 입니다\", norm=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [Soynlp] 사용 => 말뭉치 데이터셋으로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 데이터 준비\n",
    "from urllib.request import urlretrieve\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/text_data.txt\"\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    urlretrieve(\n",
    "        \"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\",\n",
    "        filename,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 데이터 처리\n",
    "from soynlp import DoublespaceLineCorpus  # 한개로 통합된 문서 데이터 분리\n",
    "from soynlp.word import WordExtractor  # 단어 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 문서 : 30091개\n"
     ]
    }
   ],
   "source": [
    "### ===> 훈련 데이터 문서 분리\n",
    "corpus = DoublespaceLineCorpus(filename)\n",
    "print(f\"훈련 데이터 문서 : {len(corpus)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.058 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "### ===> Soynlp 학습 진행\n",
    "word_extractor = WordExtractor()\n",
    "\n",
    "# 학습 진행하며 단어별 점수\n",
    "word_extractor.train(corpus)\n",
    "\n",
    "# 단어별 점수표 추출\n",
    "word_score_table = word_extractor.extract()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] - 웜\n",
      "[1] - 콕\n",
      "[2] - 멱\n",
      "[3] - 빕\n",
      "[4] - 꿇\n",
      "[5] - 졸\n",
      "[6] - 데\n",
      "[7] - 쉴\n",
      "[8] - 태\n",
      "[9] - 흐\n",
      "[10] - 넛\n",
      "[11] - 긍\n",
      "[12] - 땐\n",
      "[13] - 덤\n",
      "[14] - 관\n",
      "[15] - 런\n",
      "[16] - 램\n",
      "[17] - 길\n",
      "[18] - 욱\n",
      "[19] - 늦\n",
      "[20] - 의\n",
      "[21] - 짚\n",
      "[22] - 큰\n",
      "[23] - 웅\n",
      "[24] - 춤\n",
      "[25] - 눕\n",
      "[26] - 뱅\n",
      "[27] - 엇\n",
      "[28] - 걸\n",
      "[29] - 뭡\n",
      "[30] - 팡\n"
     ]
    }
   ],
   "source": [
    "# 단어별 점수표 확인\n",
    "for idx, key in enumerate(word_score_table.keys()):\n",
    "    print(f\"[{idx}] - {key}\")\n",
    "    if idx == 30:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 응집 확률(cohesion probability): 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도\n",
    "# - 원리 : 문자열을 문자 단위로 분리, 왼쪽부터 순서대로 문자를 추가\n",
    "#          각 문자열이 주어졌을 때 그 다음 문자가 나올 확률을 계산 / 누적곱 한 값\n",
    "# - 값이 높을수록 : 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성 높음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"바\"].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06393648140409527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"바다\"].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11518621707955429, 0.07716779358040307)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"바다에\"].cohesion_forward, word_score_table[\"바다를\"].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> Soynlp의 L tokenizer\n",
    "# - 띄어쓰기 단위로 나눈 어절 토큰 : L 토큰 + R 토큰\n",
    "# (예: '공원에' -> '공원 + 에', '공부하는' -> '공부 + 하는')\n",
    "# - 분리 기준 : 점수가 가장 높은 L 토큰을 찾아내는 원리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "# 토큰으로 쪼개기 위한 L토큰 기준값\n",
    "scores = {word: score.cohesion_forward for word, score in word_score_table.items()}\n",
    "\n",
    "l_tokenizer = LTokenizer(scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ===> 최대 점수 토크나이저\n",
    "# - 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저\n",
    "# - 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('국제사회', 0, 4, 0.20075093164820865, 4),\n",
       "  ('와', 4, 5, 0.0, 1),\n",
       "  ('우리', 5, 7, 0.4698248708580068, 2),\n",
       "  ('의', 7, 8, 0.0, 1),\n",
       "  ('노력', 8, 10, 0.17947431781701445, 2),\n",
       "  ('들로', 10, 12, 0.0, 2),\n",
       "  ('범죄', 12, 14, 0.29525483304042177, 2),\n",
       "  ('를', 14, 15, 0.0, 1),\n",
       "  ('척결', 15, 17, 0.1326530612244898, 2),\n",
       "  ('하자', 17, 19, 0.0, 2)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxscore_tokenizer = MaxScoreTokenizer(scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\", flatten=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.07856876882976202)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"국\"].cohesion_forward, word_score_table[\"국제\"].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09217735975351507, 0.20075093164820865)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"국제사\"].cohesion_forward, word_score_table[\n",
    "    \"국제사회\"\n",
    "].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17387399904982392"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_score_table[\"국제사회와\"].cohesion_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> Soynlp를 이용한 반복되는 문자 정제\n",
    "# - ㅋㅋ ㅎㅎ 등의 이모티콘의 경우 불필요하게 연속되는 경우 많음\n",
    "# - ㅋㅋ, ㅋㅋㅋ, ㅋㅋㅋㅋ와 같은 경우를 모두 서로 다른 단어로 처리하는 것은 불필요\n",
    "# >>> 반복되는 것은 하나로 정규화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "앜^^^^^^^^^\n",
      "아ㅋ영화존잼쓰ㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "import string\n",
    "\n",
    "print(string.punctuation)\n",
    "\n",
    "print(emoticon_normalize(\"앜^^^^^^^^^\", num_repeats=1))\n",
    "print(emoticon_normalize(\"앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ\", num_repeats=1))\n",
    "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ\", num_repeats=2))\n",
    "print(\n",
    "    emoticon_normalize(\n",
    "        \"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ\", num_repeats=2\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    emoticon_normalize(\n",
    "        \"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ\",\n",
    "        num_repeats=2,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n",
      "와하하핫\n",
      "와하하핫\n",
      "앜ㅋㅋ이영화존잼쓰ㅠㅠ\n",
      "앜^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize(\"와하하하하하하하하하핫\", num_repeats=2))\n",
    "print(repeat_normalize(\"와하하하하하하핫\", num_repeats=2))\n",
    "print(repeat_normalize(\"와하하하하핫\", num_repeats=2))\n",
    "print(repeat_normalize(\"앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
    "print(repeat_normalize(\"앜^^^^^^^^^\", num_repeats=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting customized_konlpy\n",
      "  Downloading customized_konlpy-0.0.64-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: Jpype1>=0.6.1 in c:\\users\\kdp-25\\.conda\\envs\\torch_nlp38\\lib\\site-packages (from customized_konlpy) (1.4.1)\n",
      "Requirement already satisfied: konlpy>=0.4.4 in c:\\users\\kdp-25\\.conda\\envs\\torch_nlp38\\lib\\site-packages (from customized_konlpy) (0.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kdp-25\\appdata\\roaming\\python\\python38\\site-packages (from Jpype1>=0.6.1->customized_konlpy) (23.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\kdp-25\\.conda\\envs\\torch_nlp38\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\kdp-25\\appdata\\roaming\\python\\python38\\site-packages (from konlpy>=0.4.4->customized_konlpy) (1.24.4)\n",
      "Downloading customized_konlpy-0.0.64-py3-none-any.whl (881 kB)\n",
      "   ---------------------------------------- 0.0/881.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 61.4/881.5 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 809.0/881.5 kB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 881.5/881.5 kB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: customized_konlpy\n",
      "Successfully installed customized_konlpy-0.0.64\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install customized_konlpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-25\\.conda\\envs\\Torch_NLP38\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.morphs(\"은경이는 사무실로 갔습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기에 사전 추가\n",
    "twitter.add_dictionary(\"은경이\", \"Noun\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.morphs(\"은경이는 사무실로 갔습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
