{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### torchtext 라이브러리로 텍스트 분류 <hr>\n",
        "- [1]단계 - 데이터 전처리 : 숫자형식으로 변환하는 것 까지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [1-1] 데이터 준비 => 내장 데이터셋 활용  \n",
        "    * AG_NEWS 데이터셋 반복자 : 레이블(label) + 문장의 튜플(tuple) 형태"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.17.2+cpu'"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 모듈 로딩 \n",
        "import torchtext\n",
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "\n",
        "torchtext.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> Pytorch 내장 데이터셋 뉴스 학습 데이터 추출\n",
        "train_iter, test_iter = AG_NEWS()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [1-2] 데이터 처리 파이프라인 준비 <hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "### ==> 특별 문자 토큰\n",
        "UNK = '<UNK>'\n",
        "PAD = '<PAD>'\n",
        "\n",
        "### ==> 토커나이즈 생성\n",
        "tokenizer = get_tokenizer('basic_english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 토큰 제너레이터 함수 : 데이터 추출하여 토큰화 \n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        # 라벨, 텍스트 --> 텍스트 토큰화\n",
        "        yield tokenizer(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 단어사전 생성\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), \n",
        "                                  specials=[UNK])\n",
        "\n",
        "### ===> <UNK> 인덱스 0으로 설정\n",
        "vocab.set_default_index(vocab[UNK])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### ===> 텍스트 >>>> 정수 인코딩\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "\n",
        "### ===> 레이틀 >>> 정수 인코딩 (0~3)\n",
        "label_pipeline = lambda x: int(x) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [1-3] 데이터 배치(batch)와 반복자 생성 <hr>\n",
        "    * torch.utils.data.DataLoader : getitem(), len() 구현한 맵 형태(map-style)\n",
        "    * collate_fn() : DataLoader로부터 생성된 샘플 배치 함수 \n",
        "        - 입력 : DataLoader에 배치 크기(batch size)가 있는 배치(batch) 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 모듈로딩\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 실행 디바이스 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### ===> DataLoader에서 배치크기만큼 데이터셋 반환 함수 \n",
        "def collate_batch(batch):\n",
        "    # 배치크기 만큼의 라벨, 텍스트, 오프셋 값 저장 변수 \n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    \n",
        "    # 1개씩 뉴스기사, 라벨 추출 해서 저장 \n",
        "    for (_label, _text) in batch:\n",
        "         # 라벨 인코딩 후 저장\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         \n",
        "         # 텍스트 인코딩 후 저장\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         \n",
        "         # 텍스트 offset 즉 , 텍스트 크기/길이 저장\n",
        "         offsets.append(processed_text.size(0))\n",
        "    \n",
        "    # 텐서화 진행     \n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    \n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [1-4]데이터셋 준비 <hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 학습용, 검증용, 테스트용 DataSet 준비 \n",
        "BATCH_SIZE = 32\n",
        "\n",
        "### 학습용, 검증용, 테스트용 Dataset, DataLoader 준비\n",
        "trainDL = DataLoader( train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch )\n",
        "testDL  = DataLoader( test_iter, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_batch )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 10]) 2\n",
            "[RNN]============\n",
            " tensor([[-0.4415, -0.6726,  0.3127],\n",
            "        [-0.8577, -0.4919,  0.4364],\n",
            "        [-0.8075, -0.4232,  0.1802],\n",
            "        [-0.6846, -0.5509,  0.0737],\n",
            "        [-0.6224, -0.3496,  0.4169],\n",
            "        [-0.7757, -0.2900,  0.3750],\n",
            "        [-0.7625, -0.5083,  0.2790],\n",
            "        [-0.8242, -0.3862,  0.3161],\n",
            "        [-0.6136, -0.2336,  0.2761],\n",
            "        [-0.5345, -0.6679, -0.3465],\n",
            "        [-0.7885, -0.6065, -0.0407],\n",
            "        [-0.7854, -0.4097, -0.0153],\n",
            "        [-0.4621, -0.3325,  0.0480],\n",
            "        [-0.7990, -0.4478, -0.1109],\n",
            "        [-0.6724, -0.6953,  0.3589],\n",
            "        [-0.8295, -0.1134,  0.5401],\n",
            "        [-0.4827, -0.3993,  0.3873],\n",
            "        [-0.4912, -0.4899,  0.1477],\n",
            "        [-0.8387, -0.4681,  0.4121],\n",
            "        [-0.7527, -0.0494,  0.4377],\n",
            "        [-0.5338, -0.5573,  0.3731],\n",
            "        [-0.8375, -0.3220,  0.2115],\n",
            "        [-0.5681, -0.5502, -0.2035],\n",
            "        [-0.6891, -0.1344,  0.0648],\n",
            "        [-0.6046, -0.5930,  0.1568],\n",
            "        [-0.7800, -0.3389,  0.0522],\n",
            "        [-0.7173, -0.4909,  0.2423],\n",
            "        [-0.7656, -0.1933,  0.4329],\n",
            "        [-0.7297, -0.3045,  0.2689],\n",
            "        [-0.7548, -0.6296,  0.3585],\n",
            "        [-0.8215, -0.5130,  0.2715],\n",
            "        [-0.8161, -0.4665, -0.1015]], grad_fn=<SqueezeBackward1>) tensor([[-0.8161, -0.4665, -0.1015]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ],
      "source": [
        "### ===> 확인\n",
        "import torch.nn as nn\n",
        "\n",
        "HIDDEN_SIZE = 3\n",
        "EMBEDD_DIM  = 10\n",
        "VOCAB_SIZE  = len(vocab) \n",
        "\n",
        "for labels, texts, offests in trainDL:\n",
        "    print(labels.shape, labels, )\n",
        "    print(texts.shape, texts, sep='\\n\\n')\n",
        "    print(offests.shape, offests)\n",
        "    \n",
        "    # embedding = nn.EmbeddingBag(VOCAB_SIZE, EMBEDD_DIM, sparse=False)\n",
        "    # result =embedding(texts, offests)\n",
        "    # print(result.shape, result.ndim)\n",
        "    \n",
        "    # rnn = nn.RNN(EMBEDD_DIM, HIDDEN_SIZE, batch_first=True)\n",
        "    # output, fn=rnn(result)\n",
        "    # print('[RNN]============\\n', output, fn)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [2] 학습 준비 <hr>\n",
        "- [2-1] 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 모듈로딩\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ==> 모델 설계\n",
        "### 입력층 : EmbeddingBag Layer - 레이어와 분류(classification) 목적을 위한 선형 레이어, 텍스트의 길이는 오프셋(offset)으로 저장, 패딩(padding) 필요하지는 않음\n",
        "### 은닉층 : Linear - 4개 클래스 분류 \n",
        "class TextModel(nn.Module):\n",
        "    def __init__(self, VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_CLASS):\n",
        "        super().__init__()\n",
        "        # 모델 구성 층 정의\n",
        "        self.embedding = nn.EmbeddingBag(VOCAB_SIZE, EMBEDD_DIM, sparse=False)\n",
        "        self.fc = nn.Linear(EMBEDD_DIM, NUM_CLASS)\n",
        "        \n",
        "        # self.embedding = nn.EmbeddingBag(VOCAB_SIZE, EMBEDD_DIM, sparse=False)\n",
        "        # self.rnn = nn.RNN(EMBEDD_DIM, HIDDEN_SIZE)\n",
        "        # self.fc = nn.Linear(HIDDEN_SIZE, NUM_CLASS)\n",
        "        self.init_weights()\n",
        "\n",
        "    # 가중치 초기화 \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    # 순방향 학습 진행\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        # output, _ = self.rnn(embedded)\n",
        "        # return self.fc(output[:, -1,:])\n",
        "        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [2-2] 학습 관련  변수 및 인스턴스 준비 <hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ==> 학습 관련 하이퍼파라미터와 인스턴스\n",
        "HIDDEN_SIZE = 3\n",
        "EMBEDD_DIM  = 64\n",
        "VOCAB_SIZE  = len(vocab) \n",
        "NUM_CLASS   = len( set( [ label for label, _ in train_iter ] ) )\n",
        "EPOCHS      = 100  \n",
        "LR          = 5 \n",
        "BATCH_SIZE  = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ==> 학습 관련 인스턴스\n",
        "MODEL = TextModel(VOCAB_SIZE, EMBEDD_DIM, \n",
        "                  HIDDEN_SIZE, NUM_CLASS).to(device)\n",
        "\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "OPTIMIZER = optim.SGD(MODEL.parameters(), lr=LR)\n",
        "SCHEDULER = optim.lr_scheduler.StepLR(OPTIMIZER, 1.0, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextModel(\n",
              "  (embedding): EmbeddingBag(95811, 64, mode='mean')\n",
              "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [2-3]학습관련 함수들 <hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 학습 진행 함수\n",
        "def train(model, dataloader, optimizer, criterion, epoch):\n",
        "    # 학습 모드\n",
        "    model.train()\n",
        "    \n",
        "    # 학습 평가 관련 변수들\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 300\n",
        "\n",
        "    # 배치 학습 진행\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        \n",
        "        label, text, offsets = label.to(device), text.to(device), offsets.to(device), \n",
        "        \n",
        "        # 학습진행\n",
        "        predicted_label = model(text, offsets)\n",
        "        #print(f'predicted_label : {predicted_label.shape}   label : {label.shape} ')\n",
        "        \n",
        "        # 손실 계산 및 W,b 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        # 기울기 소실 및 폭주 예방을 위한 양극단 값 자르기 \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        \n",
        "        # 배치 학습 평가 \n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print( f\"===> epoch {epoch:3d} | {idx:5d}/{len(dataloader):5d} batches  ===> accuracy {total_acc /total_count:8.3f}\" )\n",
        "            total_acc, total_count = 0, 0\n",
        "\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ===> 검증 및 테스트 함수\n",
        "def evaluate(model,dataloader, criterion):\n",
        "    # 검증 모드 \n",
        "    model.eval()\n",
        "    \n",
        "    # 검증 평가 관련 변수\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    # 검증 진행\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc / total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ====> 예측 함수\n",
        "def predict(model, text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        # 토큰화 > 정수 변환  > 텐서\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [3] 학습 진행 <hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------\n",
            "===> end of epoch   1     valid accuracy    0.251 \n",
            "-----------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\TORCH_NLP38\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------\n",
            "===> end of epoch   2     valid accuracy    0.253 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   3     valid accuracy    0.264 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   4     valid accuracy    0.270 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   5     valid accuracy    0.257 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   6     valid accuracy    0.266 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   7     valid accuracy    0.283 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   8     valid accuracy    0.256 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch   9     valid accuracy    0.297 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  10     valid accuracy    0.253 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  11     valid accuracy    0.252 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  12     valid accuracy    0.271 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  13     valid accuracy    0.339 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  14     valid accuracy    0.257 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  15     valid accuracy    0.276 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  16     valid accuracy    0.326 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  17     valid accuracy    0.298 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  18     valid accuracy    0.361 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  19     valid accuracy    0.251 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  20     valid accuracy    0.297 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  21     valid accuracy    0.328 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  22     valid accuracy    0.275 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  23     valid accuracy    0.294 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  24     valid accuracy    0.251 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  25     valid accuracy    0.293 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  26     valid accuracy    0.336 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  27     valid accuracy    0.378 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  28     valid accuracy    0.369 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  29     valid accuracy    0.400 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  30     valid accuracy    0.307 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  31     valid accuracy    0.283 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  32     valid accuracy    0.360 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  33     valid accuracy    0.284 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  34     valid accuracy    0.363 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  35     valid accuracy    0.391 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  36     valid accuracy    0.369 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  37     valid accuracy    0.339 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  38     valid accuracy    0.416 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  39     valid accuracy    0.388 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  40     valid accuracy    0.429 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  41     valid accuracy    0.381 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  42     valid accuracy    0.389 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  43     valid accuracy    0.357 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  44     valid accuracy    0.324 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  45     valid accuracy    0.441 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  46     valid accuracy    0.359 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  47     valid accuracy    0.425 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  48     valid accuracy    0.407 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  49     valid accuracy    0.383 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  50     valid accuracy    0.456 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  51     valid accuracy    0.388 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  52     valid accuracy    0.404 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  53     valid accuracy    0.425 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  54     valid accuracy    0.441 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  55     valid accuracy    0.348 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  56     valid accuracy    0.367 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  57     valid accuracy    0.438 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  58     valid accuracy    0.404 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  59     valid accuracy    0.415 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  60     valid accuracy    0.379 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  61     valid accuracy    0.424 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  62     valid accuracy    0.438 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  63     valid accuracy    0.416 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  64     valid accuracy    0.382 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  65     valid accuracy    0.448 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  66     valid accuracy    0.406 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  67     valid accuracy    0.466 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  68     valid accuracy    0.391 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  69     valid accuracy    0.441 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  70     valid accuracy    0.396 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  71     valid accuracy    0.477 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  72     valid accuracy    0.471 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  73     valid accuracy    0.481 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  74     valid accuracy    0.430 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  75     valid accuracy    0.495 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  76     valid accuracy    0.367 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  77     valid accuracy    0.478 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  78     valid accuracy    0.438 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  79     valid accuracy    0.401 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  80     valid accuracy    0.456 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  81     valid accuracy    0.489 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  82     valid accuracy    0.444 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  83     valid accuracy    0.422 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  84     valid accuracy    0.501 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  85     valid accuracy    0.411 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  86     valid accuracy    0.413 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  87     valid accuracy    0.492 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  88     valid accuracy    0.473 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  89     valid accuracy    0.496 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  90     valid accuracy    0.404 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  91     valid accuracy    0.505 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  92     valid accuracy    0.480 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  93     valid accuracy    0.474 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  94     valid accuracy    0.454 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  95     valid accuracy    0.499 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  96     valid accuracy    0.486 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  97     valid accuracy    0.447 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  98     valid accuracy    0.456 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch  99     valid accuracy    0.518 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "===> end of epoch 100     valid accuracy    0.485 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "### 학습 및 검증 진행\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    total_accu = train(MODEL, trainDL, OPTIMIZER, CRITERION, epoch)\n",
        "    accu_val = evaluate(MODEL, testDL, CRITERION)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        SCHEDULER.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print(\"-\" * 59)\n",
        "    print(f\"===> end of epoch {epoch:3d}     valid accuracy {accu_val:8.3f} \")\n",
        "    print(\"-\" * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [4] 평가 데이터로 모델 평가<hr>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTING......\n",
            "Test Acc :    0.628\n"
          ]
        }
      ],
      "source": [
        "print('TESTING......')\n",
        "accu_test = evaluate(MODEL, testDL, CRITERION)\n",
        "print(f'Test Acc : {accu_test:8.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- [5] 임의 데이터로 모델 평가 <hr> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEWS => World\n"
          ]
        }
      ],
      "source": [
        "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "\n",
        "\n",
        "### ==> 임의의 데이터 \n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "ex_text_str_02= \"As food prices continued to rise, consumer prices continued to rise in the 3% range for the second consecutive month.\\\n",
        "                According to the \\\"March Consumer Price Trend\\\" released by the National Statistical Office on the 2nd, the consumer price index \\\n",
        "                last month was 113.94 (2020 = 100), up 3.1% from the same month last year.\\\n",
        "                This year's consumer price growth rate increased again to 3.1% in February after recording 2.8% in January this year.\\\n",
        "                Prices of agricultural, livestock and fisheries products rose 11.7 percent year-on-year, up more than 11.4 percent from the previous month.\\\n",
        "                Among them, agricultural prices rose 20.5% year-on-year, marking the second consecutive month of increase of 20% following the previous month's 20.9%.\\\n",
        "                In particular, the price of apples rose 88.2 percent, which was larger than the previous month (71.0 percent), the largest increase ever since January 1980, \\\n",
        "                when statistics began to be compiled.\"\n",
        "\n",
        "print(f\"NEWS => {ag_news_label[predict(MODEL, ex_text_str, text_pipeline)]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
